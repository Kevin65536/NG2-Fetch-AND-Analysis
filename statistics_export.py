"""
NGAè®ºå›åˆ†æç»“æœè¯¦ç»†ç»Ÿè®¡è¡¨æ ¼å¯¼å‡ºå·¥å…·
"""

import json
import pandas as pd
import os
from collections import Counter
from datetime import datetime
import argparse


def load_classification_data(json_file):
    """åŠ è½½åˆ†ç±»æ•°æ®"""
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data


def export_category_statistics(data, output_dir="./statistics"):
    """å¯¼å‡ºåˆ†ç±»ç»Ÿè®¡è¡¨æ ¼"""
    os.makedirs(output_dir, exist_ok=True)
    
    # ç»Ÿè®¡åˆ†ç±»åˆ†å¸ƒ
    categories = {}
    for post in data['posts']:
        category = post['classification']['categories'][0] if post['classification']['categories'] else 'æœªåˆ†ç±»'
        categories[category] = categories.get(category, 0) + 1
    
    # åˆ›å»ºDataFrame
    total_posts = sum(categories.values())
    category_data = []
    for category, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):
        percentage = (count / total_posts) * 100
        category_data.append({
            'åˆ†ç±»': category,
            'å¸–å­æ•°é‡': count,
            'ç™¾åˆ†æ¯”': f"{percentage:.2f}%",
            'æ•°å€¼ç™¾åˆ†æ¯”': percentage
        })
    
    df_categories = pd.DataFrame(category_data)
    
    # ä¿å­˜ä¸ºå¤šç§æ ¼å¼
    df_categories.to_csv(f'{output_dir}/category_statistics.csv', index=False, encoding='utf-8-sig')
    df_categories.to_excel(f'{output_dir}/category_statistics.xlsx', index=False, engine='openpyxl')
    
    print(f"åˆ†ç±»ç»Ÿè®¡è¡¨æ ¼å·²ä¿å­˜åˆ°: {output_dir}/category_statistics.csv å’Œ .xlsx")
    return df_categories


def export_keyword_statistics(data, output_dir="./statistics", min_count=1):
    """å¯¼å‡ºå…³é”®è¯ç»Ÿè®¡è¡¨æ ¼ï¼ˆå®Œæ•´åˆ—è¡¨ï¼‰"""
    os.makedirs(output_dir, exist_ok=True)
    
    # ç»Ÿè®¡æ‰€æœ‰å…³é”®è¯
    all_keywords = []
    for post in data['posts']:
        keywords = post['classification'].get('keywords', [])
        all_keywords.extend(keywords)
    
    keyword_counts = Counter(all_keywords)
    
    # åˆ›å»ºå®Œæ•´å…³é”®è¯ç»Ÿè®¡è¡¨
    keyword_data = []
    total_keyword_mentions = sum(keyword_counts.values())
    
    for keyword, count in keyword_counts.most_common():
        if count >= min_count:  # è¿‡æ»¤æ‰å‡ºç°æ¬¡æ•°å¤ªå°‘çš„å…³é”®è¯
            percentage = (count / total_keyword_mentions) * 100
            keyword_data.append({
                'å…³é”®è¯': keyword,
                'å‡ºç°æ¬¡æ•°': count,
                'ç™¾åˆ†æ¯”': f"{percentage:.2f}%",
                'æ•°å€¼ç™¾åˆ†æ¯”': percentage
            })
    
    df_keywords = pd.DataFrame(keyword_data)
    
    # ä¿å­˜å®Œæ•´å…³é”®è¯åˆ—è¡¨
    df_keywords.to_csv(f'{output_dir}/keyword_statistics_full.csv', index=False, encoding='utf-8-sig')
    df_keywords.to_excel(f'{output_dir}/keyword_statistics_full.xlsx', index=False, engine='openpyxl')
    
    # åˆ›å»ºTOPå…³é”®è¯è¡¨æ ¼ï¼ˆå¤šä¸ªä¸åŒçš„TOPæ•°é‡ï¼‰
    for top_n in [10, 20, 50, 100]:
        if len(df_keywords) >= top_n:
            top_df = df_keywords.head(top_n)
            top_df.to_csv(f'{output_dir}/keyword_statistics_top{top_n}.csv', index=False, encoding='utf-8-sig')
            top_df.to_excel(f'{output_dir}/keyword_statistics_top{top_n}.xlsx', index=False, engine='openpyxl')
    
    print(f"å…³é”®è¯ç»Ÿè®¡è¡¨æ ¼å·²ä¿å­˜åˆ°: {output_dir}/keyword_statistics_*.csv å’Œ .xlsx")
    print(f"æ€»å…³é”®è¯æ•°é‡: {len(keyword_data)} (å‡ºç°æ¬¡æ•°>={min_count})")
    return df_keywords


def export_author_statistics(data, output_dir="./statistics", min_posts=1):
    """å¯¼å‡ºä½œè€…æ´»è·ƒåº¦ç»Ÿè®¡è¡¨æ ¼"""
    os.makedirs(output_dir, exist_ok=True)
    
    # ç»Ÿè®¡ä½œè€…å‘å¸–æ•°
    author_counts = Counter()
    for post in data['posts']:
        author = post.get('author', 'æœªçŸ¥ç”¨æˆ·')
        author_counts[author] += 1
    
    # åˆ›å»ºä½œè€…ç»Ÿè®¡è¡¨
    author_data = []
    total_posts = sum(author_counts.values())
    
    for author, count in author_counts.most_common():
        if count >= min_posts:
            percentage = (count / total_posts) * 100
            author_data.append({
                'ä½œè€…': author,
                'å‘å¸–æ•°é‡': count,
                'ç™¾åˆ†æ¯”': f"{percentage:.2f}%",
                'æ•°å€¼ç™¾åˆ†æ¯”': percentage
            })
    
    df_authors = pd.DataFrame(author_data)
    
    # ä¿å­˜è¡¨æ ¼
    df_authors.to_csv(f'{output_dir}/author_statistics.csv', index=False, encoding='utf-8-sig')
    df_authors.to_excel(f'{output_dir}/author_statistics.xlsx', index=False, engine='openpyxl')
    
    print(f"ä½œè€…ç»Ÿè®¡è¡¨æ ¼å·²ä¿å­˜åˆ°: {output_dir}/author_statistics.csv å’Œ .xlsx")
    print(f"æ´»è·ƒä½œè€…æ•°é‡: {len(author_data)} (å‘å¸–æ•°>={min_posts})")
    return df_authors


def export_confidence_statistics(data, output_dir="./statistics"):
    """å¯¼å‡ºç½®ä¿¡åº¦ç»Ÿè®¡è¡¨æ ¼"""
    os.makedirs(output_dir, exist_ok=True)
    
    # æ”¶é›†ç½®ä¿¡åº¦æ•°æ®
    confidence_data = []
    for i, post in enumerate(data['posts'], 1):
        confidence = post['classification'].get('confidence', 0)
        category = post['classification']['categories'][0] if post['classification']['categories'] else 'æœªåˆ†ç±»'
        keywords = ', '.join(post['classification'].get('keywords', [])[:5])  # å‰5ä¸ªå…³é”®è¯
        
        confidence_data.append({
            'åºå·': i,
            'å¸–å­æ ‡é¢˜': post.get('title', 'æ— æ ‡é¢˜')[:50] + ('...' if len(post.get('title', '')) > 50 else ''),
            'åˆ†ç±»': category,
            'ç½®ä¿¡åº¦': confidence,
            'å…³é”®è¯': keywords,
            'ä½œè€…': post.get('author', 'æœªçŸ¥')
        })
    
    df_confidence = pd.DataFrame(confidence_data)
    
    # æŒ‰ç½®ä¿¡åº¦æ’åº
    df_confidence_sorted = df_confidence.sort_values('ç½®ä¿¡åº¦', ascending=False)
    
    # ä¿å­˜è¡¨æ ¼
    df_confidence_sorted.to_csv(f'{output_dir}/confidence_statistics.csv', index=False, encoding='utf-8-sig')
    df_confidence_sorted.to_excel(f'{output_dir}/confidence_statistics.xlsx', index=False, engine='openpyxl')
    
    # åˆ›å»ºç½®ä¿¡åº¦åˆ†å¸ƒç»Ÿè®¡
    confidence_ranges = [
        (0.9, 1.0, 'é«˜ç½®ä¿¡åº¦ (0.9-1.0)'),
        (0.7, 0.9, 'ä¸­é«˜ç½®ä¿¡åº¦ (0.7-0.9)'),
        (0.5, 0.7, 'ä¸­ç­‰ç½®ä¿¡åº¦ (0.5-0.7)'),
        (0.3, 0.5, 'ä¸­ä½ç½®ä¿¡åº¦ (0.3-0.5)'),
        (0.0, 0.3, 'ä½ç½®ä¿¡åº¦ (0.0-0.3)')
    ]
    
    range_data = []
    total_posts = len(df_confidence)
    
    for min_conf, max_conf, label in confidence_ranges:
        count = len(df_confidence[(df_confidence['ç½®ä¿¡åº¦'] >= min_conf) & (df_confidence['ç½®ä¿¡åº¦'] < max_conf)])
        if min_conf == 0.9:  # æœ€é«˜èŒƒå›´åŒ…å«1.0
            count = len(df_confidence[df_confidence['ç½®ä¿¡åº¦'] >= min_conf])
        
        percentage = (count / total_posts) * 100
        range_data.append({
            'ç½®ä¿¡åº¦èŒƒå›´': label,
            'å¸–å­æ•°é‡': count,
            'ç™¾åˆ†æ¯”': f"{percentage:.2f}%",
            'æ•°å€¼ç™¾åˆ†æ¯”': percentage
        })
    
    df_ranges = pd.DataFrame(range_data)
    df_ranges.to_csv(f'{output_dir}/confidence_distribution.csv', index=False, encoding='utf-8-sig')
    df_ranges.to_excel(f'{output_dir}/confidence_distribution.xlsx', index=False, engine='openpyxl')
    
    print(f"ç½®ä¿¡åº¦ç»Ÿè®¡è¡¨æ ¼å·²ä¿å­˜åˆ°: {output_dir}/confidence_statistics.csv å’Œ .xlsx")
    print(f"ç½®ä¿¡åº¦åˆ†å¸ƒå·²ä¿å­˜åˆ°: {output_dir}/confidence_distribution.csv å’Œ .xlsx")
    return df_confidence_sorted, df_ranges


def export_category_keyword_matrix(data, output_dir="./statistics", top_keywords=20):
    """å¯¼å‡ºåˆ†ç±»-å…³é”®è¯å…³è”çŸ©é˜µè¡¨æ ¼"""
    os.makedirs(output_dir, exist_ok=True)
    
    # ç»Ÿè®¡æ¯ä¸ªåˆ†ç±»çš„å…³é”®è¯
    category_keywords = {}
    for post in data['posts']:
        category = post['classification']['categories'][0] if post['classification']['categories'] else 'æœªåˆ†ç±»'
        keywords = post['classification'].get('keywords', [])
        
        if category not in category_keywords:
            category_keywords[category] = Counter()
        
        for keyword in keywords:
            category_keywords[category][keyword] += 1
    
    # è·å–æœ€å¸¸è§çš„å…³é”®è¯
    all_keywords = Counter()
    for counter in category_keywords.values():
        all_keywords.update(counter)
    
    top_keywords_list = [kw for kw, _ in all_keywords.most_common(top_keywords)]
    categories = list(category_keywords.keys())
    
    # åˆ›å»ºçŸ©é˜µæ•°æ®
    matrix_data = []
    for category in categories:
        row_data = {'åˆ†ç±»': category}
        for keyword in top_keywords_list:
            count = category_keywords[category].get(keyword, 0)
            row_data[keyword] = count
        matrix_data.append(row_data)
    
    df_matrix = pd.DataFrame(matrix_data)
    
    # ä¿å­˜çŸ©é˜µè¡¨æ ¼
    df_matrix.to_csv(f'{output_dir}/category_keyword_matrix.csv', index=False, encoding='utf-8-sig')
    df_matrix.to_excel(f'{output_dir}/category_keyword_matrix.xlsx', index=False, engine='openpyxl')
    
    print(f"åˆ†ç±»-å…³é”®è¯çŸ©é˜µå·²ä¿å­˜åˆ°: {output_dir}/category_keyword_matrix.csv å’Œ .xlsx")
    return df_matrix


def create_summary_report(output_dir="./statistics"):
    """åˆ›å»ºæ±‡æ€»æŠ¥å‘Š"""
    os.makedirs(output_dir, exist_ok=True)
    
    report = f"""
# NGAäºŒæ¬¡å…ƒå›½å®¶åœ°ç†ç‰ˆå—è¯¦ç»†ç»Ÿè®¡æŠ¥å‘Š

## ç”Ÿæˆæ—¶é—´
{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}

## å¯¼å‡ºçš„ç»Ÿè®¡è¡¨æ ¼æ–‡ä»¶

### 1. åˆ†ç±»ç»Ÿè®¡
- `category_statistics.csv/.xlsx` - ç‰ˆå—å†…å®¹åˆ†ç±»åˆ†å¸ƒç»Ÿè®¡

### 2. å…³é”®è¯ç»Ÿè®¡
- `keyword_statistics_full.csv/.xlsx` - å®Œæ•´å…³é”®è¯åˆ—è¡¨
- `keyword_statistics_top10.csv/.xlsx` - TOP10çƒ­é—¨å…³é”®è¯
- `keyword_statistics_top20.csv/.xlsx` - TOP20çƒ­é—¨å…³é”®è¯  
- `keyword_statistics_top50.csv/.xlsx` - TOP50çƒ­é—¨å…³é”®è¯
- `keyword_statistics_top100.csv/.xlsx` - TOP100çƒ­é—¨å…³é”®è¯

### 3. ä½œè€…æ´»è·ƒåº¦ç»Ÿè®¡
- `author_statistics.csv/.xlsx` - ä½œè€…å‘å¸–æ•°é‡ç»Ÿè®¡

### 4. ç½®ä¿¡åº¦åˆ†æ
- `confidence_statistics.csv/.xlsx` - æ¯ä¸ªå¸–å­çš„è¯¦ç»†ç½®ä¿¡åº¦ä¿¡æ¯
- `confidence_distribution.csv/.xlsx` - ç½®ä¿¡åº¦åˆ†å¸ƒç»Ÿè®¡

### 5. å…³è”åˆ†æ
- `category_keyword_matrix.csv/.xlsx` - åˆ†ç±»ä¸å…³é”®è¯å…³è”çŸ©é˜µ

## æ–‡ä»¶è¯´æ˜
- `.csv` æ–‡ä»¶ï¼šé€‚åˆç”¨Excelæ‰“å¼€ï¼Œå…¼å®¹æ€§å¥½
- `.xlsx` æ–‡ä»¶ï¼šExcelåŸç”Ÿæ ¼å¼ï¼Œæ”¯æŒæ›´å¤šåŠŸèƒ½
- æ‰€æœ‰æ–‡ä»¶å‡ä½¿ç”¨UTF-8ç¼–ç ï¼Œç¡®ä¿ä¸­æ–‡æ­£ç¡®æ˜¾ç¤º

## ä½¿ç”¨å»ºè®®
1. ä½¿ç”¨Excelæ‰“å¼€.xlsxæ–‡ä»¶è¿›è¡Œæ•°æ®åˆ†æ
2. å¯ä»¥åŸºäºè¿™äº›è¡¨æ ¼åˆ›å»ºé€è§†è¡¨å’Œå›¾è¡¨
3. å…³é”®è¯ç»Ÿè®¡è¡¨å¯ç”¨äºè¯äº‘ç”Ÿæˆ
4. ç½®ä¿¡åº¦æ•°æ®å¯ç”¨äºæ¨¡å‹æ€§èƒ½è¯„ä¼°

---
æŠ¥å‘Šç”Ÿæˆäº: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}
"""
    
    with open(f'{output_dir}/ç»Ÿè®¡æŠ¥å‘Šè¯´æ˜.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"ç»Ÿè®¡æŠ¥å‘Šè¯´æ˜å·²ä¿å­˜åˆ°: {output_dir}/ç»Ÿè®¡æŠ¥å‘Šè¯´æ˜.md")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='NGAè®ºå›åˆ†æç»“æœè¯¦ç»†ç»Ÿè®¡è¡¨æ ¼å¯¼å‡ºå·¥å…·')
    parser.add_argument('-i', '--input', required=True, help='è¾“å…¥çš„JSONåˆ†ç±»ç»“æœæ–‡ä»¶')
    parser.add_argument('-o', '--output', default='./statistics', help='è¾“å‡ºç›®å½• (é»˜è®¤: ./statistics)')
    parser.add_argument('--min-keyword-count', type=int, default=1, help='å…³é”®è¯æœ€å°å‡ºç°æ¬¡æ•° (é»˜è®¤: 1)')
    parser.add_argument('--min-author-posts', type=int, default=1, help='ä½œè€…æœ€å°å‘å¸–æ•° (é»˜è®¤: 1)')
    parser.add_argument('--top-keywords', type=int, default=20, help='å…³è”çŸ©é˜µä¸­åŒ…å«çš„çƒ­é—¨å…³é”®è¯æ•°é‡ (é»˜è®¤: 20)')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.input):
        print(f"é”™è¯¯ï¼šè¾“å…¥æ–‡ä»¶ {args.input} ä¸å­˜åœ¨")
        return
    
    print(f"æ­£åœ¨å¤„ç†æ–‡ä»¶: {args.input}")
    print(f"è¾“å‡ºç›®å½•: {args.output}")
    
    # åŠ è½½æ•°æ®
    data = load_classification_data(args.input)
    print(f"åŠ è½½äº† {len(data['posts'])} ä¸ªå¸–å­çš„æ•°æ®")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output, exist_ok=True)
    
    print("\nå¼€å§‹å¯¼å‡ºç»Ÿè®¡è¡¨æ ¼...")
    
    # å¯¼å‡ºå„ç§ç»Ÿè®¡è¡¨æ ¼
    export_category_statistics(data, args.output)
    export_keyword_statistics(data, args.output, args.min_keyword_count)
    export_author_statistics(data, args.output, args.min_author_posts)
    export_confidence_statistics(data, args.output)
    export_category_keyword_matrix(data, args.output, args.top_keywords)
    
    # åˆ›å»ºæ±‡æ€»æŠ¥å‘Š
    create_summary_report(args.output)
    
    print(f"\nâœ… æ‰€æœ‰ç»Ÿè®¡è¡¨æ ¼å·²å¯¼å‡ºå®Œæ¯•ï¼")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output}")
    print(f"ğŸ“‹ è¯·æŸ¥çœ‹ '{args.output}/ç»Ÿè®¡æŠ¥å‘Šè¯´æ˜.md' äº†è§£å„æ–‡ä»¶è¯¦æƒ…")


if __name__ == "__main__":
    # å¦‚æœæ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œå°è¯•è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„åˆ†ç±»ç»“æœæ–‡ä»¶
    import sys
    if len(sys.argv) == 1:
        print("æœªæä¾›è¾“å…¥æ–‡ä»¶ï¼Œå°è¯•æŸ¥æ‰¾æœ€æ–°çš„åˆ†ç±»ç»“æœ...")
        
        # æŸ¥æ‰¾æœ€æ–°çš„åˆ†ç±»ç»“æœæ–‡ä»¶
        search_dirs = ['./test_output', './output', './production_output']
        json_files = []
        
        for search_dir in search_dirs:
            if os.path.exists(search_dir):
                files = [f for f in os.listdir(search_dir) if f.startswith('nga_classification_') and f.endswith('.json')]
                json_files.extend([os.path.join(search_dir, f) for f in files])
        
        if json_files:
            # ä½¿ç”¨æœ€æ–°çš„æ–‡ä»¶
            latest_file = sorted(json_files, key=os.path.getmtime)[-1]
            print(f"æ‰¾åˆ°æœ€æ–°æ–‡ä»¶: {latest_file}")
            
            # è‡ªåŠ¨è¿è¡Œ
            data = load_classification_data(latest_file)
            print(f"åŠ è½½äº† {len(data['posts'])} ä¸ªå¸–å­çš„æ•°æ®")
            
            output_dir = "./statistics"
            os.makedirs(output_dir, exist_ok=True)
            
            print("\nå¼€å§‹å¯¼å‡ºç»Ÿè®¡è¡¨æ ¼...")
            export_category_statistics(data, output_dir)
            export_keyword_statistics(data, output_dir)
            export_author_statistics(data, output_dir)
            export_confidence_statistics(data, output_dir)
            export_category_keyword_matrix(data, output_dir)
            create_summary_report(output_dir)
            
            print(f"\nâœ… æ‰€æœ‰ç»Ÿè®¡è¡¨æ ¼å·²å¯¼å‡ºå®Œæ¯•ï¼")
            print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        else:
            print("æœªæ‰¾åˆ°åˆ†ç±»ç»“æœæ–‡ä»¶ï¼Œè¯·æ‰‹åŠ¨æŒ‡å®šè¾“å…¥æ–‡ä»¶")
            print("ä½¿ç”¨æ–¹æ³•: python statistics_export.py -i <è¾“å…¥æ–‡ä»¶>")
    else:
        main()
